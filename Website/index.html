<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Spurious relationships in Twitter data</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<script type="text/x-mathjax-config">
  			MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		</script>
		<script type="text/javascript" async
  			src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
		</script>
		<script type="text/x-mathjax-config">
  			MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });
		</script>
	</head>
	<body>

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="#Top">Top</a></li>
					<li><a href="#Introduction">Introduction</a></li>
					<li><a href="#Data">Data</a></li>
					<li><a href="#Time">Time Series Analysis</a></li>
					<li><a href="#Results">Results</a></li>
					<li><a href="#Conclusion">Conclusion</a></li>
					<li><a href="#Acknowledgements">Acknowledgements</a></li>
					<li><a href="#Contact">Contact</a></li>
				</ul>
			</nav>

		<!-- Header -->
			<div class="wrapper style1 first">
				<article class="container" id="top">
					<div class="row">
						<div class="4u 12u(mobile)">
							<span class="image fit"><img src="correlations.png" alt="" /></span>
						</div>
						<div class="8u 12u(mobile)">
							<header>
								<h1><strong>Spurious relationships</strong></h1>
								<h2>in Twitter data</h2>
							</header>
							
							<p><h6>Claudio Bruderer, Andrina Nicola, Anna Weigel</h6></p>

							<p>For our search of spurious relationships within Big Data, we used a set of unfiltered tweets covering a time period of six months and a list of pre-defined keywords. Here, we present the details of our analysis and our results.
							</p>

							<a href="#Results" class="button scrolly">See our results</a>
							<ul class="social">
							</ul>
						</div>
					</div>
				</article>
			</div>

		<!-- Introduction -->
			<div class="wrapper style2">
				<article id="Introduction">
					<header>
						<h1>Introduction</h1>
						<!--<p>Odio turpis amet sed consequat eget posuere consequat.</p>-->
					</header>
					<div class="container">
						<div class="row">
							<section class="box style1">
								<p>
								We have entered the era of Big Data and the wealth of information available to us entails its own new challenges. Relationships between quantities, whether real or without any obvious causal link, will naturally arise if the data sets are large enough (for examples see <a href="http://tylervigen.com/spurious-correlations">Tyler Vigen, Spurious correlations)</a>). Even though we might be inclined to interpret apparent links between measurements, a correlation does not imply causation. One needs to find a way to distinguish spurious relationships between measurements from those with a causal link, and quantify the frequency of chance correlations occurring.
								</p>

								<p>
								Based on a list of pre-defined keywords and Twitter data, we aim to show that relationships between quantities without any obvious causal link can be identified in large data sets. 
								We use a Twitter dataset which contains unfiltered tweets between May 2014 - July 2014 and September 2014 - December 2014. For each day, we determine the number of tweets containing one of our pre-defined keywords. We then measure and quantify the time-correlation functions between the popularity of various keywords. To test our method we recover and quantify expected correlations between synonyms or related keywords. We additionally investigate and discuss the performance of different correlation measures.

								</p>
							</section>
						</div>
					</div>
				</article>
			</div>

		<!-- Data -->
			<div class="wrapper style2">
				<article id="Data">
					<header>
						<h1>Data</h1>
					</header>
					<div class="container">
						<div class="row">
							<section class="box style1">
								<h3>Data set</h3>
								<p>In order to identify relationships between words, we need a suitable data set containing a large amount of text data and covering an extended period of time. Data from all major social media platforms primarily using text as a medium (e.g. <a href="http://www.esa.int/Our_Activities/Space_Science/Rosetta">Twitter</a>, <a href="http://www.esa.int/Our_Activities/Space_Science/Rosetta">Facebook</a>, and Reddit \cite{reddit}) satisfy these conditions.</p>

								<p>We decided to apply our analysis on Twitter data, which has been previously gathered by an ETH research group. This data set was created via the public <a href="https://dev.twitter.com/streaming/public">Twitter Stream</a>, which downloads $1\%$ of the tweets posted at that moment without applying any further filtering, and covers the years 2012-2014. We analyse a subset of the whole data set, which contains data of the months May, 2014 - July, 2014 and September, 2014 - December, 2014. These data have been converted to Parquet files, thus simplyfing reading in the data.</p>

								<h3>Keyword Selection</h3>
								<p>In our analysis we select one hundred keywords. All these keywords are listed in below:</p>
								<section align="left">
									<p><b>Terrorism / Religion:</b> isis, terrorism, arab, spring, attack, god, christian, allah, islam</p>
									<p><b>Refugees:</b> syria, refugees, migrants, africa, italy, ethiopia, asylum, unhcr, immigration, foreigners</p>
									<p><b>Ebola:</b> ebola, guinea, sierra, leone, liberia, virus, epidemic, vaccine, who</p>
									<p><b>Influenza:</b> influenza, flu, birds, swine, pig</p>
									<p><b>Science:</b> bitcoin, rosetta, comet, higgs, climate, doomsday, maya, curiosity, sandy, hurricane</p>
									<p><b>Discrimination:</b> black, white, crowded, left, right</p>
									<p><b>Malaysian Airlines:</b> mh17, mh370</p>
									<p><b>Ukraine/Crimea:</b> ukraine, crimea, russia</p>
									<p><b>Politics:</b> snowden, nsa, obama, putin, mandela, nelson, pope, unemployment</p>
									<p><b>Countries/Cities:</b> europe, usa, philippines, sochi, olympics, geneva, boston, london</p>
									<p><b>Technology:</b> apple, linux, pc, google, iphone, galaxy, watch, facebook, twitter, whatsapp</p>
									<p><b>Food/Trends:</b> vegan, gluten, vegetarian, meat, pasta, banana</p>
									<p><b>Family:</b> family, divorce, marriage, wedding, holidays</p>
									<p><b>Everyday life:</b> homework, television, coffee, tea, school, work, teacher, sports, jogging, marathon</p>
								</section>

								<p>To choose these keywords, we applied different criteria. First, we identified major events that happened during the period for which we have access to twitter data (May 2014 - July 2014 and September 2014 - December 2014). For these topics, we then selected related words, on purpose also including synonyms. Besides these <i>major events categories</i> we also chose words related to long-term trends we <i>it a priori</i> expect to find in the data (e.g. <i>Food / Trends</i>, <i>Refugees</i>, <i>Politics</i>). Furthermore, we include a group of keywords on <i>Everyday life</i> for which we <i>it a priori</i> do not expect to see strong trends.</p>

								<p>These selection criteria were chosen to address various problems. First, by picking words related to major events localized in time (e.g.  <a href="http://www.esa.int/Our_Activities/Space_Science/Rosetta">Rosetta satellite dispatching Philae lander</a>), we are able to test our pipeline and assert that this <i>it a priori</i> expected quick rise in mentions on social media platforms is identified in our data as well. Second, by including several synonyms, it is reasonable to expect certain correlations between the keywords, hence allowing us to validate our analysis in a second, independent way. Third, the keywords for which we do not <i>it a priori</i> expect the number of mentions to display a significant structure over time (e.g. <i>Everyday life</i>), should only weakly correlate with other keywords displaying more structure.</p>

								<p>We note however that there are caveats in this type of analysis. Many words have different meanings and could thus potentially correlate or not correlate with other words depending on which meaning is more common. As an example, we include <i>who</i> in our analysis. While it is primarily used as a pronoun, it is also the abbreviation of the World Health Organization <a href="http://www.who.int/en/">WHO</a>. Due to the Ebola outbreak in Western Africa in 2014, we expect this secondary meaning to modulate the number of mentions over time, and potentially display correlations with related words (e.g. <i>ebola</i>). Other examples of words with multiple meanings include <i>right</i> (opposite of wrong; political perspective; direction) and <i>left</i> (past participle of leave; political perspective; direction).</p>

								<h3>Data analysis</h3>
								<p>We use the <a href="https://www.python.org">Python</a> front end of <a href="http://spark.apache.org">Apache Spark</a> called <b>pyspark</b> to analyse the twitter data. The data set is read in and then filtered to contain only non-empty tweets. As a next step, the timestamp is adjusted to be in a more accessible format, which encodes only the day of the year and the year, and the tweets are split up into individual words and converted to be only lowercase. For all words we compute jointly the number of mentions per day. As a last step, we filter to only recover the statistics for our keywords, where we also take the keywords into account if they are used as a hashtags, and save the results.</p>

								<h3>Data completeness</h3>
								<p>The streaming of Twitter data was interrupted several times during the period the data were collected. Thus, minutes, hours, or even days are missing. While missing days are trivial to identify, doing so for partly incomplete daily data is more complicated. These days however would induce systematic biases to the analysis, as for all keywords the number of mentions decreases at the same time, thus inducing a strong correlation in otherwise potentially uncorrelated data.</p>

								<table style="width:100%" id="fig1">
								  <tr>
								    <td><img src="images/incomplete_data.pdf" alt="incomplete_data"></td>
								  </tr>
								  <tr>
								    <td>Histogram of the occurences of specific indices, which correspond to individual days, for which the number of mentions of a keyword is below the average minus the standard deviation for this keyword. The threshold is set at 20.</td>
								  </tr>
								</table>


							</section>
						</div>
					</div>
				</article>
			</div>

		<!-- Time Series Analysis -->
			<div class="wrapper style2">
				<article id="Time">
					<header>
						<h1>Time Series Analysis</h1>
					</header>
					<div class="container">
						<div class="row">
							<section class="box style1">
								<p>The main results of the data reduction explained in the previous section, are time series of the occurrence of each of the 100 keywords in the queried twitter dataset. In order to identify relationships between different keywords, we compare their occurrence frequencies using three different methods based on the Pearson correlation coefficient and k means clustering.</p>

								<h3>Correlation between stationary time series</h3>
								<p>We can determine the amount of linear dependence between two time series $X_{i}$ and $X_{j}$ using the correlation coefficient $\rho$. The correlation $\rho(\Delta t)$ between two time series is a function of the time lag $\Delta t$ between the two and is defined as (<a href="https://stat.ethz.ch/education/semesters/ss2014/atsa/Scriptum_v140523.pdf">Marcel Dettling, Applied Time Series Analysis, SS 2014, Zurich University of Applied Sciences</a>)
								\begin{equation}
								\rho_{ij}(\Delta t) = \langle (X_{i, t}-\bar{X}_{i}) (X_{j, t+\Delta t}-\bar{X}_{j}) \rangle, \label{eq:corrcoef}
								\end{equation} 
								where $\langle ... \rangle$ denotes the ensemble average. For $\Delta t = 0$ we recover the usual correlation coefficient, whereas for $\Delta t \neq 0$, $\rho_{ij}(\Delta t)$ quantifies the amount of linear dependence between shifted time series. If the two time series are equal i.e. $i = j$, then we recover the autocorrelation function of the time series, which quantifies the amount of linear dependence in the time series itself. In order to compare the correlation between different time series, it is customary to normalise Eq.~\ref{eq:corrcoef} by the variance of the two time series i.e. (<a href="https://stat.ethz.ch/education/semesters/ss2014/atsa/Scriptum_v140523.pdf">Marcel Dettling, Applied Time Series Analysis</a>)
								\begin{equation}
								\rho_{ij}(\Delta t) = \frac{\langle (X_{i, t}-\bar{X}_{i}) (X_{j, t+\Delta t}-\bar{X}_{j}) \rangle}{\sqrt{\langle (X_{i, t}-\bar{X}_{i}) (X_{i, t}-\bar{X}_{i}) \rangle \langle (X_{j, t}-\bar{X}_{j}) (X_{j, t}-\bar{X}_{j}) \rangle}}. \label{eq:corrcoef1}
								\end{equation}
								</p>

								<p>
								When performing time series analyses we generally do not have access to the ensemble averages of the series, but we need to estimate the auto and cross correlations from the samples we have at hand. In order to be able to estimate the auto- or cross correlation using Eq.~\ref{eq:corrcoef}, the ensemble average needs to equal the sample mean i.e. the values of both time series at all times $t$ need to identically distributed random variables. This is equivalent to requiring both time series $X_{i}$, $X_{j}$ to be stationary, which means that their mean $\mu$, variance $\sigma^{2}$ and autocorrelation function $\rho_{ii}(\Delta t)$ do not depend explicitly on time $t$
								\begin{align}
								\mu &= \langle X_{i, t} \rangle, \\
								\sigma^{2} &=  \langle (X_{i, t}-\bar{X})^{2} \rangle \\
								\rho_{ii}(\Delta t) &= \frac{\langle (X_{i, t}-\bar{X}_{i}) (X_{i, t+\Delta t}-\bar{X}_{i}) \rangle}{\sqrt{\langle (X_{i, t}-\bar{X}_{i}) (X_{i, t}-\bar{X}_{i}) \rangle \langle (X_{i, t+\Delta t}-\bar{X}_{i}) (X_{i, t+\Delta t}-\bar{X}_{i}) \rangle}}. 
								\end{align} 
								Only in this case, can we replace the ensemble averages in Equations \ref{eq:corrcoef} and \ref{eq:corrcoef1} with the sample means. This leads to the following estimators for the auto and cross correlation functions (<a href="https://stat.ethz.ch/education/semesters/ss2014/atsa/Scriptum_v140523.pdf">Marcel Dettling, Applied Time Series Analysis</a>):
								\begin{align}
								\rho_{ii}(\Delta t) &= \frac{\sum_{t=1}^{n-\Delta t} (X_{i, t}-\bar{X}_{i}) (X_{i, t+\Delta t}-\bar{X}_{i})}{\sum_{t=1}^{n} (X_{i, t}-\bar{X}_{i})^{2}} \\
								\rho_{ij}(\Delta t) &= \frac{\sum_{t=1}^{n-\Delta t} (X_{i, t}-\bar{X}_{i}) (X_{j, t+\Delta t}-\bar{X}_{j})}{\sqrt{\sum_{t=1}^{n} (X_{i, t}-\bar{X}_{i})^{2}\sum_{t=1}^{n} (X_{j, t}-\bar{X}_{j})^{2}}}.
								\end{align}
								<p>

								<h3>Differencing of non-stationary time series</h3>
								<p>
								We do not expect the occurrences of keywords in twitter data to be stationary time series, since the mean occurrence of any keyword will for example depend on world events, its popularity and also on the number of people using twitter. We can roughly assess if any time series is stationary by visually inspecting the time series plot and also by computing its autocorrelation function $\rho(\Delta t)$. Non stationary time series are generally characterised by clear patterns in the autocorrelation functions because consecutive values are strongly correlated through the common trend.
								</p>

								<p>
								In order to be able to quantify the correlation between non stationary time series we need to make the series stationary prior to evaluating Equations \ref{eq:corrcoef} and \ref{eq:corrcoef1}. The most basic form is called differencing, which allows us to transform time series with a slow trend to stationary series. A time series with a trend can be written as (<a href="https://stat.ethz.ch/education/semesters/ss2014/atsa/Scriptum_v140523.pdf">Marcel Dettling, Applied Time Series Analysis</a>)
								\begin{equation}
								X_{i, t} = T_{i, t} + R_{i, t},
								\end{equation} 
								where $T_{i, t}$ denotes the time series' trend and $R_{i, t}$ are random fluctuations around this trend. These fluctuations $R_{i, t}$ are generally correlated random variables with mean zero. If the time series varies slowly, we can remove the trend by considering the differenced time series instead of the initial one. The differenced time series is defined as (<a href="https://stat.ethz.ch/education/semesters/ss2014/atsa/Scriptum_v140523.pdf">Marcel Dettling, Applied Time Series Analysis</a>)
								\begin{equation}
								D_{i, t} = X_{i, t+1}- X_{i, t}.
								\end{equation} 
								If $T_{i, t}$ is slowly varying, this transformed time series will only capture the random variations around the global trend and will thus approximately be stationary.
								</p>

								<p>
								For non stationary time series, we can thus first perform differencing and then compute the auto and cross correlations between the differenced time series. This will encode the amount of linear dependence between changes in one time series from its global trend and changes in the second.
								</p>

								<p>
								In order to quantify the significance of both the auto- and cross correlations, we need to compare the measured values to the expected values for uncorrelated time series. For uncorrelated time series, which are a sequence of IID variables we expect both for the auto and cross correlations $\rho(\Delta t) = 0$ with a variance of $\sigma^{2}(\rho(\Delta t)) = \frac{1}{n}$, where $n$ denotes the number of samples used to estimate the correlation (<a href="https://stat.ethz.ch/education/semesters/ss2014/atsa/Scriptum_v140523.pdf">Marcel Dettling, Applied Time Series Analysis</a>). For simplicity, we will call a cross-correlation between two time series significant if its value exceeds $1.96 \sigma(\rho(\Delta t))$ (i.e. the $95 \%$ confidence limits), even though we do not expect the differenced time series to be perfect IID processes. 
								</p>

								<h3>Missing data</h3>
								<p>
								The above considerations assume that there is no missing time series data, which is rarely the case in reality. Several pieces of data are missing in the twitter dataset. First of all we do not have access to data for most of August 2014 and furthermore there are several days missing thoughout. In order to be able to analyse the data, we therefore fill the missing values using random samples drawn from a normal distribution with the mean and variance of the respective time series. This procedure will keep mean and standard deviation constant and will not introduce any correlations between different time series.
								</p>

								<p>
								In order to find relations between keywords, we will proceed in two steps: for illustration purposes we will compute the cross correlation between all the time series (filled as explained above) regardless of stationarity for timelags $-10 \leq \Delta t \leq 10$. We will then compute the autocorrelation function of all the series and recompute the correlation coefficients using the differenced time series for non stationary processes. For both methods, we assign the highest correlation coefficient (regardless of timelag $\Delta t$) to each pair and compare the results obtained with these two measures.
								</p>

							</section>
						</div>
					</div>
				</article>
			</div>

		<!-- Results -->
			<div class="wrapper style2">
				<article id="Results">
					<header>
						<h1>Results</h1>
					</header>
					<div class="container">
						<div class="row">
							<section class="box style1">
									<p>
									The occurrence of different keywords over time displays different behaviour depending on the keyword. Keywords from the everyday life and family sections for example feature stationary time series with little to no variation. On the other hand, keywords associated to major events show significant trends and structure. Examples for both these cases are shown in Figures <a href="#fig2">2</a> and <a href="#fig3">3</a>.  The Figures show the absolute and relative time series for the words <i>banana</i> and <i>MH17</i>  respectively. <i>MH17</i>  is the abbreviation for the Malaysian airlines flight 17, which was shot down over the Ukraine on July, 17th 2014. We see that the mentions of <i>MH17</i>  are concentrated in this period while the word banana appears with a constant frequency over the 6 months we have analysed. Another interesting example is the word <i>apple</i> , which denotes the fruit as well as the company. We would expect the frequency of the word <i>apple</i>  to be fairly time-independent, but from the plot we see that the number of mentions features a strong peak in September, 2014. This is probably caused by apple holding its keynote speech during this period of the year. This example shows that many words can have different meanings depending on the context or language which can cause <i>a priori</i>  unexpected features in the time series. 
									</p>
									<p><h3>Fig 2: Absolute number of keyword occurrences as a function of time:</h3><p>
									<table style="width:100%" id="fig2">
									  <tr>
									    <td><img src="images/banana_absolute.pdf" alt="banana_absolute"></td>
									    <td><img src="images/mh17_absolute.pdf" alt="mh17_absolute"></td>
									  </tr>
									  <tr>
									    <td>Occurrence frequency for <i>banana</i>.</td>
									    <td>Occurrence frequency for <i>MH17</i>.</td>
									  </tr>
									  <tr>
									    <td  colspan='2'><img src="images/apple_absolute.pdf" alt="apple_absolute"></td>
									  </tr>
									  <tr>
									    <td  colspan='2'>Occurrence frequency for <i>apple</i>.</td>
									  </tr>
									</table>

									<p><h3>Fig 3: Mean subtracted number of keyword occurrences as a function of time normalised by the standard deviation of the time series:</h3><p>
									<table style="width:100%" id="fig3">
									  <tr>
									    <td><img src="images/banana.pdf" alt="banana"></td>
									    <td><img src="images/mh17.pdf" alt="mh17"></td>
									  </tr>
									  <tr>
									    <td>Occurrence frequency for <i>banana</i>.</td>
									    <td>Occurrence frequency for <i>MH17</i>.</td>
									  </tr>
									  <tr>
									    <td  colspan='2'><img src="images/apple.pdf" alt="apple"></td>
									  </tr>
									  <tr>
									    <td  colspan='2'>Occurrence frequency for <i>apple</i>.</td>
									  </tr>
									</table>

									<p>
										From Figures <a href="#fig2">2</a> and <a href="#fig3">3</a>, we see that in general, the time series are not stationary. We therefore transform all the time series by differencing, as outlined in Eq.~\ref{eq:diff}. The differenced time series for the keyword <i>MH17</i> are shown in Fig. <a href="#fig4">4</a> along with its autocorrelation function. We see that the differenced time series is largely stationary, even though <i>MH17</i>. is one of the most strongly varying keywords in our sample. This is confirmed by the autocorrelation function.
									</p>

									<p><h3>Fig 4: Differenced time series and autocorrelation function for <i>MH17</i>. The dashed lines indicate $95 \%$ confidence intervals for IID data:</h3><p>
									<table style="width:100%" id="fig4">
									  <tr>
									    <td><img src="images/mh17_diff.pdf" alt="mh17_diff"></td>
									    <td><img src="images/mh17_acf.pdf" alt="mh17_acf"></td>
									  </tr>
									  <tr>
									    <td>Differenced time series for <i>MH17</i>.</td>
									    <td>Autocorrelation function for <i>MH17</i>.</td>
									  </tr>
									</table>

									<h3>Here are some examples of expected and unexpected correlations and non-correlations:</h3>
									<table style="width:100%" align="left" border='1'>
									  <tr>
									    <th colspan='2'><h4>Expected Correlation</h4></th>
									    <th colspan='2'><h4>Expected Non-correlation</h4></th>	
									  </tr>
									  <tr align="left">
									    <td><b>Keywords</b></td>
									    <td><b>Value</b></td>	
									    <td><b>Keywords</b></td>
									    <td><b>Value</b></td>	
									  </tr>
									  <tr align="left">
									    <td>Nelson & Mandela</td>
									    <td>?</td>		
									    <td>Climate & Banana</td>
									    <td>?</td>
									  </tr>
									  <tr align="left">
									    <td>MH17 & Ukraine</td>
									    <td>?</td>		
									    <td>WhatsApp & Jogging</td>
									    <td>?</td>
									  </tr>
									  <tr align="left">
									    <td>Refugees & Syria</td>
									    <td>?</td>		
									    <td>Wedding & Ukraine</td>
									    <td>?</td>
									  </tr>
									</table>
									<table style="width:100%" align="left" border='1'>
									  <tr>	
									    <th colspan='2'><h4>Unexpected Correlation</h4></th>
									    <th colspan='2'><h4>Unexpected Non-correlation</h4></th>
									  </tr>
									  <tr align="left">
									    <td><b>Keywords</b></td>
									    <td><b>Value</b></td>	
									    <td><b>Keywords</b></td>
									    <td><b>Value</b></td>	
									  </tr>
									  <tr align="left">
									    <td>MH370 & Swine</td>
									    <td>?</td>		
									    <td>Migrants & Refugees</td>
									    <td>?</td>
									  </tr>
									  <tr align="left">
									    <td>Linux & Allah</td>
									    <td>?</td>		
									    <td>Snowden & Russia</td>
									    <td>?</td>
									  </tr>
									  <tr align="left">
									    <td>Vegetarian & London</td>
									    <td>?</td>		
									    <td>Comet & Rosetta</td>
									    <td>?</td>
									  </tr>
									</table>
									
							</section>
						</div>
					</div>
				</article>
			</div>

			<article id="frequency_plot">
				<header>
					<link rel="stylesheet" href="https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.css" type="text/css" />
					<link rel="stylesheet" href="https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.css" type="text/css" />
					<script src="https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.js"></script>
					<script src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.js"></script>
				</header>
					
				<div class="container">
					<div class="plotdiv" id="7f786d23-563e-413a-ab53-e35116feaa13"></div>
					<script type="text/javascript" src="frequency_plot.js"></script>
				</div>
			</article>
 
			<article id="correlations_plot">
				<header>
					<link rel="stylesheet" href="https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.css" type="text/css" />
					<link rel="stylesheet" href="https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.css" type="text/css" />
					<script src="https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.js"></script>
					<script src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.js"></script>
				</header>
				<div class="container">
					<div class="plotdiv" id="43dad00a-2ebd-4a05-9260-32cad621663c"></div>
					<script type="text/javascript" src="correlations_raw.js"></script>
				</div>
			</article>

			<article id="correlations_plot">
				<header>
					<link rel="stylesheet" href="https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.css" type="text/css" />
					<link rel="stylesheet" href="https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.css" type="text/css" />
					<script src="https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.js"></script>
					<script src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.js"></script>
				</header>
				<div class="container">
					<div class="plotdiv" id="efe437c4-a27b-4600-9318-b1cb3ac2afd2"></div>
					<script type="text/javascript" src="correlations_diff.js"></script>
				</div>
			</article>


		<!-- Conclusion -->
		<!-- Time Series Analysis -->
			<div class="wrapper style2">
				<article id="Conclusion">
					<header>
						<h1>Conclusion</h1>
					</header>
					<div class="container">
						<div class="row">
							<section class="box style1">
								<p>
								In this project we analysed roughly six months of unfiltered twitter data by querying the tweets for a set of 100 predefined keywords. We aimed at recovering correlations between the occurrence frequencies of related keywords and showing that spurious relationships can be detected in large datasets. We used both the time series of the number of tweets per day containing a particular keyword and its differenced counterpart to compute correlation coefficients for pairs of keywords. 
								</p>

								<p>
								While we found large correlation coefficients for <i>a priori</i> expected keyword pairs, we also measured a significant number of unexpected and probably spurious correlations.	
								</p>

							</section>
						</div>
					</div>
				</article>
			</div>

		<!-- Acknowledgements -->
			<div class="wrapper style4">
				<article id="Acknowledgements">
					<header>
						<h2>Acknowledgements</h2>
						This project was part of the lecture <i>Data Science in Techno-Socio-Economic Systems</i> given by Dr. Evangelos Pournaras, Prof. Dr. Dirk Helbing and Dr. Izabela Moise at ETH Zurich during the spring semester 2016. We would like to thank Dr. Izabela Moise and Dr. Rok Roskar for the valuable guidance and helpful discussions. We used <a href="http://spark.apache.org">Apache Spark</a> to query the Twitter data, and <a href="https://www.python.org">Python</a> and <a href="http://bokeh.pydata.org/en/latest/">Bokeh</a> for the data analysis and visualization. The website was built on a <a href="http://html5up.net">HTML5 Up</a> template.
					</header>
				</article>
			</div>	

		<!-- Contact -->
			<div class="wrapper style4">
				<article id="Contact">
					<ul class="social">
						<table style="width:100%">
						  <tr>
						    <td><h3>Claudio Bruderer</h3></td>
						    <td><h3>Andrina Nicola</h3></td> 
						    <td><h3>Anna Weigel</h3></td>
						  </tr>
						  <tr>
						    <td>
						    	<li><a href="https://twitter.com/cbruderer" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
						    	<p>@cbruderer</p>
						    </td>
						    <td>
						    	<li><a href="" class="icon fa-twitter"><span class="label">Twitter</span></a></li>...<p></p>
						    </td> 
						    <td>
						    	<li><a href="https://twitter.com/AnnaKWeigel" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
						    	<p>@annakweigel</p>	

						    </td>
						  </tr>
						  <tr>
						  	<td>
						  		claudio.bruderer[at]phys.ethz[dot]ch
						  	</td>
						  	<td>
						  		andrina.nicola[at]phys.ethz[dot]ch
						  	</td>
						  	<td>
						  		anna.weigel[at]phys.ethz[dot]ch
						  	</td>
						  </tr>
						  <tr>
						  	<td>
						  		Institute for Astronomy, ETH Zurich
						  	</td>
						  	<td>
						  		Institute for Astronomy, ETH Zurich
						  	</td>
						  	<td>
						  		Institute for Astronomy, ETH Zurich
						  	</td>
						  </tr>
						</table>
						<!--
						<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
						<li><a href="#" class="icon fa-dribbble"><span class="label">Dribbble</span></a></li>
						<li><a href="#" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="#" class="icon fa-tumblr"><span class="label">Tumblr</span></a></li>
						<li><a href="#" class="icon fa-google-plus"><span class="label">Google+</span></a></li>
						<li><a href="#" class="icon fa-github"><span class="label">Github</span></a></li>
						<li><a href="#" class="icon fa-rss"><span>RSS</span></a></li>
						<li><a href="#" class="icon fa-instagram"><span>Instagram</span></a></li>
						<li><a href="#" class="icon fa-foursquare"><span>Foursquare</span></a></li>
						<li><a href="#" class="icon fa-skype"><span>Skype</span></a></li>
						<li><a href="#" class="icon fa-soundcloud"><span>Soundcloud</span></a></li>
						<li><a href="#" class="icon fa-youtube"><span>YouTube</span></a></li>
						<li><a href="#" class="icon fa-blogger"><span>Blogger</span></a></li>
						<li><a href="#" class="icon fa-flickr"><span>Flickr</span></a></li>
						<li><a href="#" class="icon fa-vimeo"><span>Vimeo</span></a></li>
						-->
					</ul>
					<hr />				
				<footer>
					<ul id="copyright">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</footer>
				</article>
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/skel-viewport.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>